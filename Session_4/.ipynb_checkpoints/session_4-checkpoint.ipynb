{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with NLTK\n",
    "### The first step is to type a special command at the Python prompt which tells the interpreter to load some texts for us to explore: from nltk.book import *. This says \"from NLTK's book module, load all items\". After printing a welcome message, it loads the text of several books (this will take a few seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Any time we want to find out about these texts, we just have to enter their names at the Python prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Text\n",
    "### There are many ways to examine the context of a text apart from simply reading it. A concordance view shows us every occurrence of a given word, together with some context. Here we look up the word monstrous in Moby Dick by entering text1 followed by a period, then the term concordance, and then placing \"monstrous\" in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Practice*\n",
    "### 1) Try searching for other words\n",
    "### 2) Try searches on some of the other texts we have included. For example, search \"Sense and Sensibility\" for the word \"affection\" or search the book of \"Genesis\" to find out how long some people lived\n",
    "### 3) You could look at text4, the \"Inaugural Address Corpus\", to see examples of English going back to 1789, and search for words like \"nation\", \"terror\", \"god\" to see how these words have been used differently over time\n",
    "### 4) text5 contains the \"NPS Chat Corpus\", where you could search this for unconventional words like \"im\", \"ur\", \"lol\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A concordance permits us to see words in context. For example, we saw that monstrous occurred in contexts such as *the ___ pictures* and *a ___ size*. What other words appear in a similar range of contexts? We can find out by appending the term *similar* to the name of the text in question, then inserting the relevant word in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe that we get different results for different texts. Austen uses this word quite differently from Melville; for her, \"monstrous\" has positive connotations, and sometimes functions as an intensifier like the word \"very\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The term *common_contexts* allows us to examine just the contexts that are shared by two or more words, such as \"monstrous\" and \"very\". We have to enclose these words by square brackets as well as parentheses, and separate them with a comma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_it i_you i_to i_being you_me\n"
     ]
    }
   ],
   "source": [
    "text5.common_contexts([\"hate\", \"love\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Practice*\n",
    "### Pick another pair of words and compare their usage in two different texts, using the *similar()* and *common_contexts()* functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text. In the figure, we see some striking patterns of word usage over the last 220 years (in an artificial text constructed by joining the texts of the Inaugural Address Corpus end-to-end). You can produce this plot as shown below. As before, take care to get the quotes, commas, brackets and parentheses exactly right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEWCAYAAABWn/G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpaVE4+ZmWX1PySL8UrifWTlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17edfb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Practice*\n",
    "### Try more words (e.g., liberty, constitution), and different texts. Can you predict the dispersion of a word before you view it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Vocabulary\n",
    "### The most obvious fact about texts that emerges from the preceding examples is that they differ in the vocabulary they use. In this section we will see how to use the computer to count the words in a text in a variety of useful ways. As before, you will jump right in and experiment with the Python interpreter, even though you may not have studied Python systematically yet. Test your understanding by modifying the examples, and trying the exercises in hte assignment.\n",
    "\n",
    "### Let's begin by finding out the length of a text from start to finish, in terms of the words and punctuation symbols that appear. We use the term len to get the length of something, which we'll apply here to the book of Genesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So Genesis has 44,764 words and punctuation symbols, or \"tokens\". A token is the technical name for a sequence of characters — such as *hairy*, *his*, or *:)* — that we want to treat as a group. When we count the number of tokens in a text, say, the phrase \"to be or not to be\", we are counting occurrences of these sequences. Thus, in our example phrase there are two occurrences of *to*, two of *be*, and one each of *or* and *not*. But there are only four distinct vocabulary items in this phrase. How many distinct words does the book of Genesis contain? To work this out in Python, we have to pose the question slightly differently. The vocabulary of a text is just the *set* of tokens that it uses, since in a set, all duplicates are collapsed together. In Python we can obtain the vocabulary items of *text3* with the command: *set(text3)*. When you do this, many screens of words will fly past. Now try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By wrapping sorted() around the Python expression *set(text3)*, we obtain a sorted list of vocabulary items, beginning with various punctuation symbols and continuing with words starting with A. All capitalized words precede lowercase words. We discover the size of the vocabulary indirectly, by asking for the number of items in the set, and again we can use len to obtain this number. Although it has 44,764 tokens, this book has only 2,789 distinct words, or \"word types.\" A *word type* is the form or spelling of the word independently of its specific occurrences in a text — that is, the word considered as a unique item of vocabulary. Our count of 2,789 items will include punctuation symbols, so we will generally call these unique items *types* instead of word types.\n",
    "### Now, let's calculate a measure of the lexical richness of the text. The next example shows us that the number of distinct words is just 6% of the total number of words, or equivalently that each word is used 16 times on average (remember if you're using Python 2, to start with *from __future__ import division*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3)) / len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's focus on particular words. We can count how often a word occurs in a text, and compute what percentage of the text is taken up by a specific word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text4.count('a') / len(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Practice*\n",
    "### How many times does the word lol appear in text5? How much is this as a percentage of the total number of words in this text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.count(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5640968673628082"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*text5.count(\"lol\")/len(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may want to repeat such calculations on several texts, but it is tedious to keep retyping the formula. Instead, you can come up with your own name for a task, like \"lexical_diversity\" or \"percentage\", and associate it with a block of code. Now you only have to type a short name instead of one or more complete lines of Python code, and you can re-use it as often as you like. The block of code that does a task for us is called a *function*, and we define a short name for our function with the keyword def. The next example shows how to define two new functions, *lexical_diversity()* and *percentage()*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the definition of *lexical_diversity()*, we specify a parameter named *text*. This parameter is a \"placeholder\" for the actual text whose lexical diversity we want to compute, and reoccurs in the block of code that will run when the function is used. Similarly, *percentage()* is defined to take two parameters, named *count* and *total*.\n",
    "\n",
    "### Once Python knows that *lexical_diversity()* and *percentage()* are the names for specific blocks of code, we can go ahead and use these functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13477005109975562"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing and Tagging Words\n",
    "### Back in elementary school you learnt the difference between nouns, verbs, adjectives, and adverbs. These \"word classes\" are not just the idle invention of grammarians, but are useful categories for many language processing tasks. As we will see, they arise from simple analysis of the distribution of words in text. The goal of this section is to answer the following questions:\n",
    "\n",
    "### 1) What are lexical categories and how are they used in natural language processing? \n",
    "### 2) What is a good Python data structure for storing words and their categories? \n",
    "### 3) How can we automatically tag each word of a text with its word class?\n",
    "\n",
    "### The process of classifying words into their *parts of speech* and labeling them accordingly is known as *part-of-speech tagging*, *POS-tagging*, or *simply tagging*. Parts of speech are also known as *word classes* or *lexical categories*. The collection of tags used for a particular task is known as a *tagset*. Our emphasis in this chapter is on exploiting tags, and tagging text automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Tagger\n",
    "### A part-of-speech tagger, or POS-tagger, processes a sequence of words, and attaches a part of speech tag to each word (don't forget to *import nltk*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "text = word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we see that *and* is CC, a coordinating conjunction; *now* and *completely* are RB, or adverbs; *for* is IN, a preposition; *something* is NN, a noun; and *different* is JJ, an adjective.\n",
    "\n",
    "### NLTK provides documentation for each tag, which can be queried using the tag, e.g. *nltk.help.upenn_tagset('RB')*. Some corpora have README files with tagset documentation, see *nltk.corpus.???.readme()*, substituting in the name of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('RB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at another example, this time including some homonyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that *refuse* and *permit* both appear as a present tense verb (VBP) and a noun (NN). E.g. *refUSE* is a verb meaning \"deny,\" while *REFuse* is a noun meaning \"trash\" (i.e., they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical categories like \"noun\" and part-of-speech tags like NN seem to have their uses, but the details will be obscure to many readers. You might wonder what justification there is for introducing this extra level of information. Many of these categories arise from superficial analysis the distribution of words in text. Consider the following analysis involving *woman* (a noun), *bought* (a verb), *over* (a preposition), and *the* (a determiner). The *text.similar()* method takes a word *w*, finds all contexts w1*w*w2, then finds all words *w'* that appear in the same context, i.e. w1*w'*w2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world house family child country boy\n",
      "state job place way war girl work word\n"
     ]
    }
   ],
   "source": [
    "text.similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made said done put had seen found given left heard was been brought\n",
      "set got that took in told felt\n"
     ]
    }
   ],
   "source": [
    "text.similar('bought')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in on to of and for with from at by that into as up out down through\n",
      "is all about\n"
     ]
    }
   ],
   "source": [
    "text.similar('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a his this their its her an that our any all one these my in your no\n",
      "some other and\n"
     ]
    }
   ],
   "source": [
    "text.similar('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe that searching for *woman* finds nouns; searching for *bought* mostly finds verbs; searching for *over* generally finds prepositions; searching for *the* finds several determiners. \n",
    "\n",
    "### A tagger can also model our knowledge of unknown words, e.g. we can guess that scrobbling is probably a verb, with the root scrobble, and likely to occur in contexts like he was scrobbling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_add',\n",
       " '_c2f',\n",
       " '_delimiter',\n",
       " '_encoding',\n",
       " '_f2c',\n",
       " '_file',\n",
       " '_fileids',\n",
       " '_get_root',\n",
       " '_init',\n",
       " '_map',\n",
       " '_para_block_reader',\n",
       " '_pattern',\n",
       " '_resolve',\n",
       " '_root',\n",
       " '_sent_tokenizer',\n",
       " '_sep',\n",
       " '_tagset',\n",
       " '_unload',\n",
       " '_word_tokenizer',\n",
       " 'abspath',\n",
       " 'abspaths',\n",
       " 'categories',\n",
       " 'citation',\n",
       " 'encoding',\n",
       " 'ensure_loaded',\n",
       " 'fileids',\n",
       " 'license',\n",
       " 'open',\n",
       " 'paras',\n",
       " 'raw',\n",
       " 'readme',\n",
       " 'root',\n",
       " 'sents',\n",
       " 'tagged_paras',\n",
       " 'tagged_sents',\n",
       " 'tagged_words',\n",
       " 'unicode_repr',\n",
       " 'words']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
